{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LT healthcare services\n",
    "\n",
    "Prepared by [**K.Clemons**](mailto:kimberly.clemons@ext.ec.europa.eu) and [**J.Grazzini**](mailto:jacopo.grazzini@ec.europa.eu) ([_Eurostat_](https://ec.europa.eu/eurostat)).\n",
    "\n",
    "## Introdution\n",
    "\n",
    "This notebook illustrates the way to produce *ad-hoc* harmonised data collected from LT national authority. It shows how data can be automatically harmonised, using single-use script-based approachr or a reusable metadata-based approach.\n",
    "\n",
    "**Table of contents**\n",
    "\n",
    "* [Setting and checking the environment](#environment).\n",
    "* [Ad-hoc data ingestion, exploration and processing](#ad-hoc).\n",
    "* [Metadata-based semi-automated processing](#metadata-processing).\n",
    "* [Full automation](#automation).\n",
    "* [Customised processing](#customisation).\n",
    "\n",
    "## Setting the environment <a id=\"environment\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'basic-services'\n",
    "\n",
    "import os, sys\n",
    "import functools\n",
    "import inspect\n",
    "import json\n",
    "from pprint import pprint as pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACILITY      = 'HCS'\n",
    "COUNTRY, LANG = 'Lithuania', 'lt'\n",
    "CC            = 'LT'\n",
    "IFILE         = 'Hospitals_2018.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- src rel. path: \u001b[1mbasic-services/src/python/pyeufacility\u001b[0m\n",
      "- data rel. path: \u001b[1mbasic-services/data/healthcare/raw\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "THISDIR = os.getcwd()\n",
    "SRCPATH = os.path.abspath('../../../src/python/pyeufacility/')\n",
    "DATAPATH = os.path.abspath('../../../data/healthcare/raw/') \n",
    "# or       '/Users/<username>/basic-services/data/healthcare/%s' % CC\n",
    "\n",
    "try:\n",
    "    print(\"- src rel. path: \\033[1m%s%s\\033[0m\" % (PROJECT, SRCPATH.split(PROJECT)[1])) \n",
    "    print(\"- data rel. path: \\033[1m%s%s\\033[0m\" % (PROJECT, DATAPATH.split(PROJECT)[1])) \n",
    "except:\n",
    "    print(\"current path: \\033[1m%s\\033[0m\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad-hoc data ingestion, exploration and processing <a id=\"ad-hoc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mInput dataset:\u001b[0m \u001b[1m/data/healthcare/raw/Hospitals_2018.xlsx\u001b[0m\n",
      "\u001b[4mInput dataset columns:\u001b[0m \u001b[1m['Code of municipality', 'Municipality', 'ID', 'parent_ID', 'Code of legal entity', 'Subordination: 1-national (MoH), 3-municipality, 8-private, 9-other ministries (not MoH)', 'type_code', 'type_name', 'Level: 1-national, 2-regional, 3-municipality, 4-nursing, 5-other public and specialized, 6-private', 'Name', 'Address', 'Number of beds at the end of the 2018']\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code of municipality</th>\n",
       "      <th>Municipality</th>\n",
       "      <th>ID</th>\n",
       "      <th>parent_ID</th>\n",
       "      <th>Code of legal entity</th>\n",
       "      <th>Subordination: 1-national (MoH), 3-municipality, 8-private, 9-other ministries (not MoH)</th>\n",
       "      <th>type_code</th>\n",
       "      <th>type_name</th>\n",
       "      <th>Level: 1-national, 2-regional, 3-municipality, 4-nursing, 5-other public and specialized, 6-private</th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Number of beds at the end of the 2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Vilnius</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124364561</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>1</td>\n",
       "      <td>Vilniaus Universiteto ligoninė Santaros klinikos</td>\n",
       "      <td>Santariškių 2, Vilnius LT-08661</td>\n",
       "      <td>1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>Vilnius</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>302620298</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>1</td>\n",
       "      <td>Vilniaus Universiteto ligoninės Santaros klini...</td>\n",
       "      <td>Santariškių 7, Vilnius  LT-08406</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>Vilnius</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>124243848</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>1</td>\n",
       "      <td>Respublikinė Vilniaus universitetinė ligoninė</td>\n",
       "      <td>Šiltnamių 29, Vilnius</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>Vilnius</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>191744287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>1</td>\n",
       "      <td>Vilniaus Universiteto ligoninės Žalgirio klinika</td>\n",
       "      <td>Žalgirio 117, Vilnius</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>Vilnius</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>124247526</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>psychiatry</td>\n",
       "      <td>5</td>\n",
       "      <td>Respublikinė Vilniaus psichiatrijos ligoninė</td>\n",
       "      <td>Parko g. 21, Vilnius</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code of municipality Municipality  ID  parent_ID  Code of legal entity  \\\n",
       "0                   101      Vilnius   1          0             124364561   \n",
       "1                   101      Vilnius   5          1             302620298   \n",
       "2                   101      Vilnius  32          0             124243848   \n",
       "3                   101      Vilnius   3          0             191744287   \n",
       "4                   101      Vilnius  10          0             124247526   \n",
       "\n",
       "   Subordination: 1-national (MoH), 3-municipality, 8-private, 9-other ministries (not MoH)  \\\n",
       "0                                                  1                                          \n",
       "1                                                  1                                          \n",
       "2                                                  1                                          \n",
       "3                                                  1                                          \n",
       "4                                                  1                                          \n",
       "\n",
       "   type_code   type_name  \\\n",
       "0          1     general   \n",
       "1          1     general   \n",
       "2          1     general   \n",
       "3          1     general   \n",
       "4         19  psychiatry   \n",
       "\n",
       "   Level: 1-national, 2-regional, 3-municipality, 4-nursing, 5-other public and specialized, 6-private  \\\n",
       "0                                                  1                                                     \n",
       "1                                                  1                                                     \n",
       "2                                                  1                                                     \n",
       "3                                                  1                                                     \n",
       "4                                                  5                                                     \n",
       "\n",
       "                                                Name  \\\n",
       "0   Vilniaus Universiteto ligoninė Santaros klinikos   \n",
       "1  Vilniaus Universiteto ligoninės Santaros klini...   \n",
       "2      Respublikinė Vilniaus universitetinė ligoninė   \n",
       "3   Vilniaus Universiteto ligoninės Žalgirio klinika   \n",
       "4       Respublikinė Vilniaus psichiatrijos ligoninė   \n",
       "\n",
       "                            Address  Number of beds at the end of the 2018  \n",
       "0   Santariškių 2, Vilnius LT-08661                                   1356  \n",
       "1  Santariškių 7, Vilnius  LT-08406                                    515  \n",
       "2             Šiltnamių 29, Vilnius                                    673  \n",
       "3             Žalgirio 117, Vilnius                                     58  \n",
       "4              Parko g. 21, Vilnius                                    542  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import xlrd\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install xlrd\n",
    "\n",
    "def adhoc_load(file): # dumb function we aim at reusing later on\n",
    "    return pd.read_excel(file, header = 2) \n",
    "\n",
    "file = os.path.join(DATAPATH, IFILE)\n",
    "print(\"\\033[4mInput dataset:\\033[0m \\033[1m%s\\033[0m\" % file.split(PROJECT)[1])\n",
    "df_src = adhoc_load(file)\n",
    "\n",
    "print(\"\\033[4mInput dataset columns:\\033[0m \\033[1m%s\\033[0m\" % list(df_src.columns))\n",
    "# pprint(df_src.dtypes)\n",
    "df_src.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `adhoc_preparation` method below enables us to clean the dataset, add/rename columns, derive information, *etc...*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Municipality</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_ID</th>\n",
       "      <th>type_code</th>\n",
       "      <th>facility_type</th>\n",
       "      <th>name</th>\n",
       "      <th>Address</th>\n",
       "      <th>cap_beds</th>\n",
       "      <th>country</th>\n",
       "      <th>public_private</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vilnius</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>Vilniaus Universiteto ligoninė Santaros klinikos</td>\n",
       "      <td>Santariškių 2, Vilnius LT-08661</td>\n",
       "      <td>1356</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>public</td>\n",
       "      <td>Santariškių 2, Vilnius LT-08661, Lithuania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vilnius</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>Vilniaus Universiteto ligoninės Santaros klini...</td>\n",
       "      <td>Santariškių 7, Vilnius  LT-08406</td>\n",
       "      <td>515</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>public</td>\n",
       "      <td>Santariškių 7, Vilnius  LT-08406, Lithuania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vilnius</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>Respublikinė Vilniaus universitetinė ligoninė</td>\n",
       "      <td>Šiltnamių 29, Vilnius</td>\n",
       "      <td>673</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>public</td>\n",
       "      <td>Šiltnamių 29, Vilnius, Lithuania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vilnius</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>Vilniaus Universiteto ligoninės Žalgirio klinika</td>\n",
       "      <td>Žalgirio 117, Vilnius</td>\n",
       "      <td>58</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>public</td>\n",
       "      <td>Žalgirio 117, Vilnius, Lithuania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vilnius</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>psychiatry</td>\n",
       "      <td>Respublikinė Vilniaus psichiatrijos ligoninė</td>\n",
       "      <td>Parko g. 21, Vilnius</td>\n",
       "      <td>542</td>\n",
       "      <td>Lithuania</td>\n",
       "      <td>public</td>\n",
       "      <td>Parko g. 21, Vilnius, Lithuania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Municipality  id  parent_ID  type_code facility_type  \\\n",
       "0      Vilnius   1          0          1       general   \n",
       "1      Vilnius   5          1          1       general   \n",
       "2      Vilnius  32          0          1       general   \n",
       "3      Vilnius   3          0          1       general   \n",
       "4      Vilnius  10          0         19    psychiatry   \n",
       "\n",
       "                                                name  \\\n",
       "0   Vilniaus Universiteto ligoninė Santaros klinikos   \n",
       "1  Vilniaus Universiteto ligoninės Santaros klini...   \n",
       "2      Respublikinė Vilniaus universitetinė ligoninė   \n",
       "3   Vilniaus Universiteto ligoninės Žalgirio klinika   \n",
       "4       Respublikinė Vilniaus psichiatrijos ligoninė   \n",
       "\n",
       "                            Address  cap_beds    country public_private  \\\n",
       "0   Santariškių 2, Vilnius LT-08661      1356  Lithuania         public   \n",
       "1  Santariškių 7, Vilnius  LT-08406       515  Lithuania         public   \n",
       "2             Šiltnamių 29, Vilnius       673  Lithuania         public   \n",
       "3             Žalgirio 117, Vilnius        58  Lithuania         public   \n",
       "4              Parko g. 21, Vilnius       542  Lithuania         public   \n",
       "\n",
       "                                         place  \n",
       "0   Santariškių 2, Vilnius LT-08661, Lithuania  \n",
       "1  Santariškių 7, Vilnius  LT-08406, Lithuania  \n",
       "2             Šiltnamių 29, Vilnius, Lithuania  \n",
       "3             Žalgirio 117, Vilnius, Lithuania  \n",
       "4              Parko g. 21, Vilnius, Lithuania  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adhoc_preparation(df):\n",
    "    df['country'] = COUNTRY\n",
    "    df['public_private'] = (df['Level: 1-national, 2-regional, 3-municipality, 4-nursing, '\n",
    "                                '5-other public and specialized, 6-private']\n",
    "                             .apply(lambda x: 'private' if x==6 else 'public')\n",
    "                            )\n",
    "\n",
    "    df.rename(columns = {'ID':                                    'id',\n",
    "                         'Name':                                  'name',\n",
    "                         #'Address':                               'address',\n",
    "                         'Number of beds at the end of the 2018': 'cap_beds',\n",
    "                         'type_name':                             'facility_type'}, \n",
    "               inplace = True, errors = 'ignore') \n",
    "\n",
    "    df['place'] = df[['Address', 'country']].apply(', '.join, 1)\n",
    "\n",
    "    df.drop(columns = ['Subordination: 1-national (MoH), 3-municipality, 8-private, 9-other ministries (not MoH)',\n",
    "                       'Level: 1-national, 2-regional, 3-municipality, 4-nursing, '\n",
    "                       '5-other public and specialized, 6-private',\n",
    "                       'Code of legal entity', 'Code of municipality'],\n",
    "             inplace = True, errors = 'ignore')\n",
    "\n",
    "df1 = df_src.copy()\n",
    "adhoc_preparation(df1)\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a geocoder/geolocator using the [`geopy`](https://geopy.readthedocs.io/en/stable/#) package, possibly inserting an API key to the geocoding service if needed (below, `OSM` and `Bing` are considered for the geocoders `gcNominatim` and `gcBing` respectively):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import geopy\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install geopy\n",
    "finally:\n",
    "    from geopy import geocoders, extra\n",
    "\n",
    "key = None\n",
    "try:\n",
    "    assert key is not None\n",
    "except:\n",
    "    gcNominatim = functools.partial(geocoders.Nominatim(user_agent = PROJECT).geocode, \n",
    "                                   language = LANG)\n",
    "else:\n",
    "    gcBing = geocoders.Bing(user_agent = PROJECT, timeout = 100, api_key = key).geocode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note some way to circumvent the geocoder limitations (this may not be needed for all geocoders):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location: \u001b[1mSantariškių 2, Vilnius LT-08661, Lithuania\u001b[0m\n",
      "lat/lon coordinates: \u001b[1m(54.75234945,25.277250069302262)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"location: \\033[1m%s\\033[0m\" % df1.iloc[0]['place'])\n",
    "try:\n",
    "    location = gcNominatim(df1.iloc[0]['place'])\n",
    "    assert location is not None\n",
    "except:\n",
    "    try:\n",
    "        location = gcNominatim(df1.iloc[0]['Address'])\n",
    "        assert location is not None \n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        print(\"lat/lon coordinates: \\033[1m(%s,%s)\\033[0m\" \n",
    "              % (location.latitude, location.longitude))\n",
    "else:\n",
    "    print(\"lat/lon coordinates: \\033[1m(%s,%s)\\033[0m\" \n",
    "          % (location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `adhoc_geolocation` method then applies the geocoder to the newly built `'place'` variable and extract the latitude/longitude coordinates from the geocoder answers. It also handles some negative responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "GeocoderTimedOut",
     "evalue": "Service timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1319\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0;32m-> 1422\u001b[0;31m                                                   server_hostname=server_hostname)\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         )\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    869\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mtimeout\u001b[0m: _ssl.c:1059: The handshake operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/site-packages/geopy/geocoders/base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[0;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 543\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1361\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1362\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error _ssl.c:1059: The handshake operation timed out>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGeocoderTimedOut\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-81162fe90436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'__coord__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# or keep it for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0madhoc_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-81162fe90436>\u001b[0m in \u001b[0;36madhoc_location\u001b[0;34m(df, geolocator)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madhoc_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeolocator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcNominatim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__coord__'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'place'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeolocator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__coord__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__coord__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         long_address = (df[['name', 'Address', 'country']]\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/site-packages/geopy/geocoders/osm.py\u001b[0m in \u001b[0;36mgeocode\u001b[0;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         return self._parse_json(\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_geocoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         )\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/miniconda3/lib/python3.7/site-packages/geopy/geocoders/base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[0;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"timed out\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mGeocoderTimedOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Service timed out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m\"unreachable\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mGeocoderUnavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Service not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGeocoderTimedOut\u001b[0m: Service timed out"
     ]
    }
   ],
   "source": [
    "def adhoc_location(df, geolocator = gcNominatim):\n",
    "    df['__coord__'] = df['place'].apply(geolocator)\n",
    "    if df['__coord__'].isnull().any():\n",
    "        index = df[df['__coord__'].isnull()].index\n",
    "        long_address = (df[['name', 'Address', 'country']]\n",
    "                         .apply(', '.join, 1)\n",
    "                        ) # of use when geocoding fails\n",
    "        df.loc[index, '__coord__'] = long_address.loc[index].apply(geolocator)\n",
    "    df['lat'], df['lon'] = zip(*df['__coord__']\n",
    "                               .apply(lambda x: (x.latitude, x.longitude) if x != None else (np.nan, np.nan))\n",
    "                              )\n",
    "    df.drop(columns = '__coord__', inplace = True, errors = 'ignore') # or keep it for display\n",
    "\n",
    "adhoc_location(df1)   \n",
    "df1[['lat', 'lon']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally save the output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFILE = '%s_geolocated.csv' % CC\n",
    "df1.to_csv(OFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata-based semi-automated processing<a id=\"metadata-processing\"></a>\n",
    "\n",
    "We aim at automating the above operations into a transparent reusable process, while ensuring the potential evolvability of this process (*e.g.*, when data change). For that purpose, we adopt the metadata-based approach implemented throughout the [`pyeudatanat`](https://github.com/eurostat/pyEUDatNat) and [`pyeufacility`](https://github.com/eurostat/pyeufacility) packages.\n",
    "\n",
    "For a proper import of the packages and setup of the environment, see [the dedicated cells](https://github.com/eurostat/basic-services/blob/master/src/python/notebooks/01_HCS_generic_example_CZ.ipynb#environment) of the [`01_HCS_generic_example_CZ.ipynb` notebook](https://github.com/eurostat/basic-services/blob/master/src/python/notebooks/01_HCS_generic_example_CZ.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pyeudatnat\n",
    "except ImportError:\n",
    "    !{sys.executable} -m pip install git+https://github.com/eurostat/pyEUDatNat.git\n",
    "finally:\n",
    "    from pyeudatnat import misc, io, text, base\n",
    "\n",
    "try:\n",
    "    import pyeufacility\n",
    "except ImportError:\n",
    "    # !{sys.executable} -m pip install git+https://github.com/eurostat/basic-services.git\n",
    "    # if you launch it from the notebooks/ directory, try for instance:\n",
    "    pardir = os.path.abspath(os.path.join(THISDIR, '../'))\n",
    "    sys.path.insert(0,pardir)\n",
    "finally:\n",
    "    from pyeufacility import config, hcs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the LT-specific module `hcs.LThcs` (file `LThcs.py`), we define a series of operations (like the ad-hoc ones above) necessary to 'prepare' the dataset. Those operations are implemented as methods of the `hcs.LThcs.Prepare_data` class (although the accompanying `hcs.LThcs.prepare_data` will be considered, see below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prep_data = hcs.LThcs.Prepare_data\n",
    "preparator = Prep_data()\n",
    "\n",
    "pred = lambda o: (inspect.ismethod(o) or inspect.isfunction(o)) and not o.__name__.startswith('__')\n",
    "print(\"\\033[4mMethods in '%s' class: \\033[1m%s\\033[0m \" \n",
    "      % (Prep_data.__name__, [l[0] for l in inspect.getmembers(Prep_data, predicate = pred)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the `split_Adr` function splits any address into its `['street', 'number', 'postcode', 'city']` components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_Adr = preparator.split_Adr\n",
    "assert callable(split_Adr) is True\n",
    "\n",
    "print(\"\\033[4mMethod: \\033[1m'%s'\\033[0m\" % split_Adr.__name__)\n",
    "print(inspect.getsource(split_Adr))\n",
    "\n",
    "df2 = df_src.copy()\n",
    "\n",
    "print(\"\\033[4mExample of use of '%s':\\033[0m\" % split_Adr.__name__)\n",
    "print(\" * input complete address: \\033[1m'%s'\\033[0m\" % df2['Address'].iloc[0])\n",
    "print(\" * output decomposed address: \\033[1m'%s'\\033[0m\" \n",
    "      % list(split_Adr(df2['Address'].iloc[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the `set_adress` method applies the `split_Adr` function on the `'Address'` column, throughout all raws of the input table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_address = preparator.set_address\n",
    "assert callable(set_address) is True\n",
    "print(\"\\033[4mMethod: \\033[1m'%s'\\033[0m\" % set_address.__name__)\n",
    "print(inspect.getsource(set_address))\n",
    "\n",
    "set_address(df2)\n",
    "\n",
    "print(\"\\033[4mExample of use of '%s':\\033[0m\" % set_address.__name__)\n",
    "df2[['postcode', 'city', 'street', 'number']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the `set_pp` method classifies `'Level'` column into `['public', 'private']` types, throughout all raws of the input table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_pp = preparator.set_pp\n",
    "assert callable(set_pp) is True\n",
    "print(\"\\033[4mMethod: \\033[1m'%s'\\033[0m\" % set_pp.__name__)\n",
    "print(inspect.getsource(set_pp))\n",
    "\n",
    "set_pp(df2)\n",
    "\n",
    "print(\"\\033[4mExample of use of '%s':\\033[0m\" % set_pp.__name__)\n",
    "df2[['public_private']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the basic 'prepare' operations implemented in the `'LThcs'` module, some additional information required for data integration are parsed through the `'LThcs.json'` metadata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METAPATH = os.path.dirname(inspect.getfile(hcs))\n",
    "print(\"- Source directory with HCS country-specific metadata: \\033[1m'%s'\\033[0m\" \n",
    "      % METAPATH.split(PROJECT)[1])\n",
    "\n",
    "try:\n",
    "    meta = os.path.join(METAPATH,'%shcs.json' % CC)\n",
    "    assert os.path.exists(meta)\n",
    "except (AssertionError,FileNotFoundError):\n",
    "    print(\"! No HCS metadata JSON-file found for '%s'!\" % CC)\n",
    "else:\n",
    "    print(\"- Source HCS metadata JSON-file for '%s': \\033[1m'%s'\\033[0m\" \n",
    "          % (CC, meta.split(PROJECT)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta, 'r') as fp:\n",
    "    metadata = io.Json.load(fp)\n",
    "\n",
    "print(\"\\033[4mCountry-specific metadata for %s:\\033[0m\" % CC)\n",
    "pprint(metadata) # print(io.Json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact one-to-one columns matching from the input raw table to the output harmonised dataset is provided through the `'index'` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[4mInput/output colum matching:\\033[0m\")\n",
    "pprint({k:v for (k,v) in metadata['index'].items() if v is not None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the two resources above, we can design the LT country-specific ingestion design:\n",
    "* a `LTFacility` class is derived from the `pyeudatnat.base.BaseDatNat` class using the `pyeufacility.config.facilityFactory` constructor method,\n",
    "* the `metadata` information (as made available through the `'LThcs.json'` file) is parsed to the `LTFacility` constructor, \n",
    "* the 'prepare' operations (as implemented in the `hcs.LThcs.Prepare_data` class) are 'attached' to the `LTFacility` class by overriding the original abstract `BaseDatNat.prepare_data` with the `'hcs.LThcs.prepare_data'` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the LT HCS specific class while parsing the metadata\n",
    "LTFacility = config.facilityFactory(cat = FACILITY, meta = metadata)\n",
    "# override the prepare_data abstract method\n",
    "LTFacility.prepare_data = LThcs.prepare_data\n",
    "\n",
    "pprint(LTFacility.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, we create an instance `lt` of `LTFacility` to handle these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = LTFacility()\n",
    "\n",
    "print(\"\\033[4mInput data source:\\033[0m %s\" % lt.file.split(PROJECT)[1])\n",
    "\n",
    "print(\"\\n\\033[4mOutput %s configuration metadata:\\033[0m\" % FACILITY)\n",
    "pprint(lt.config.to_dict()) # or simply: print(lt.config)\n",
    "\n",
    "assert ({k:v for (k,v) in lt.meta.to_dict().items() if v is not None}\n",
    "        ==  # comparing non empty options\n",
    "        {k:v for (k,v) in metadata.items() if v is not None})\n",
    "print(\"\\n\\033[4mInput %s country specific metadata:\\033[0m\" % CC)\n",
    "pprint(lt.meta.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method `load_data` is used to load the data into the instance dataframe `lt.data`. At this stage, all necessary information to run this operation is available in the `metadata` of the `lt` instance. Besides the file source (`'file'` and `'path'` fields), the option `options['load']` also provides relevant settings for retrieving the (Excel) input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ({k:v for (k,v) in lt.options.items() if v not in ({},None)}\n",
    "        ==  # comparing non empty options\n",
    "        {k:v for (k,v) in lt.meta['options'].items() if v not in ({},None)})\n",
    "\n",
    "print(\"\\n\\033[4mLoading options:\\033[0m %s\" % lt.options.get('load')) \n",
    "lt.load_data() # try also: lt.load_data(header = 2)\n",
    "# you can add some keyword arguments necessary to load the data: they will override the default settings\n",
    "\n",
    "cols = lt.data.columns\n",
    "print(\"\\n\\033[4mInput loaded data columns:\\033[0m %s\" % list(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the `prepare_data` operations that were introduced through the overriding `Prepare_data` class introduced above. This particularly entails the prior creation of the `['number', 'street', 'postcode', 'city']` fields that will be later used for geolocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\033[4mOverriding method: \\033[1m'%s'\\033[0m\" % LThcs.prepare_data.__name__)\n",
    "# print(inspect.getsource(LThcs.prepare_data))\n",
    "\n",
    "print(\"\\n\\033[4mPre-processing options:\\033[0m %s\" % lt.options.get('prepare')) \n",
    "lt.prepare_data()\n",
    "\n",
    "print(\"\\n\\033[4mUpdated data columns:\\033[0m %s\" % list(set(lt.data.columns) ^ set(cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previously created fields, the geolocation operation is run through the call to `locate_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[4mSupported geoservices\\033[0m (to be complemented - see geopy):\")\n",
    "pprint(pyeudatnat.geo.CODERS)\n",
    "\n",
    "print(\"\\n\\033[4mGeocoding options:\\033[0m %s\" % lt.options.get('locate')) \n",
    "lt.locate_data() \n",
    "# use also: lt.locate_data(place = ['number', 'street', 'postcode', 'city'], gc = {'Bing': 'your-key'})\n",
    "\n",
    "lt.data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the formatting/harmonisation operated in the `format_data` method consists mainly in basic renaming/casting of existing and new fields/columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.format_data()\n",
    "lt.data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full automation <a id=\"automation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarise, the entire data preparation, processing and harmonisation of the input dataset consists in running sequentially the following operations:\n",
    "```python\n",
    "# country-specific class definition\n",
    "LTFacility = config.facilityFactory(cat = 'HCS', meta = metadata)\n",
    "# facility instance creation\n",
    "lt = LTFacility()\n",
    "# data handling, geocoding and formatting\n",
    "lt.load_data()\n",
    "lt.prepare_data()\n",
    "lt.locate_data()\n",
    "lt.format_data()\n",
    "```\n",
    "where processing options/parameters of the various operations above are parsed through the configuration and metadata attributes `meta`, `config` and `options` of the input facility instance, or passed directly to the different methods. \n",
    "\n",
    "Overall, the above stepwise process is fully automated once all necessary options/parameters have been informed in the metadata. Namely, it is possible to automatically run the entire processing using the self-contained `harmonise` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyeufacility import harmonise\n",
    "lt = harmonise.run('HCS', country = \"LT\", on_disk = True, dest = 'LTtest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, whenever the geographical coordinates are set in the dataset, it is possible to easily retrieve a `GeoDataFrame` instance from the facility instance using the `to_geodf` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolt = lt.to_geodf(latlon = ['lat', 'lon'], crs = \"EPSG:4326\")\n",
    "\n",
    "geolt[['lat', 'lon', 'geometry']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, one can use the geoinformation for basic exploratory visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import Map, GeoJson, features\n",
    "  \n",
    "vilnius = [54.6872, 25.2797]\n",
    "zoom = 11\n",
    "nsample = 10\n",
    "\n",
    "# gjsonlt = json.dumps(io.Frame.to_geojson(lt.data.iloc[0:(nsample-1),:], latlon = ['lat', 'lon']))\n",
    "gjsonlt = geolt[~(geolt.lon.isna() | geolt.lat.isna())]\n",
    "gjsonlt = gjsonlt.iloc[0:(nsample-1),:].to_json()\n",
    "          \n",
    "m = Map(location = vilnius, zoom_start = zoom)\n",
    "GeoJson(gjsonlt, name = 'LT hospital',\n",
    "    tooltip=features.GeoJsonTooltip(fields=['hospital_name','facility_type','cap_beds'], localize=True)).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customised processing <a id=\"customisation\"></a>\n",
    "\n",
    "Using class methods overriding, it is actually possible to customise any of the operations run throughout the entire harmonisation process. Actually, the default implementations made available in the metadata file `LThcs.py` (currently, `Prepare_data` and `prepare_data`) can be overriden themselves. \n",
    "\n",
    "This way, any of the loading (`load_data`), pre-processing (`prepare_data`), geolocalisation (`locate_data`) and formatting (`format_data`) operations can be customised/updated. New operations can be added, as listed below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[4mCustomisable operatios:\\033[0m \\033[1m%s\\033[0m\" % pyeudatnat.base.PROCESSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations that are updated and reported in the `LThcs.py` module will be uploaded by the automated `harmonise` process to override the abstract/original methods. Otherwise, overriding can be explicitly performed. \n",
    "\n",
    "In the following, we reuse the basic functions used for the [ad-hoc processing](#ad-hoc) throughout the entire workflow. For this purpose a new class `Another_LTFacility` needs to be introduced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Another_LTFacility = config.facilityFactory(cat = FACILITY, meta = metadata)\n",
    "\n",
    "def another_loader(instance): # instance is like 'self'...\n",
    "    instance.data = adhoc_load(instance.file)\n",
    "Another_LTFacility.load_data = another_loader\n",
    "\n",
    "def another_preparator(instance):\n",
    "    instance.data = instance.data.head(10) # reduce the dataset dimension\n",
    "    adhoc_preparation(instance.data)\n",
    "Another_LTFacility.prepare_data = another_preparator\n",
    "\n",
    "def another_locator(instance):\n",
    "    adhoc_location(instance.data)\n",
    "Another_LTFacility.locate_data = another_locator\n",
    "\n",
    "# pprint(Another_LTFacility.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these methods do not use the metadata information (which is instead hardly encoded in the core of the functions). Still, the same stepwise approach is adopted to process the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_lt = Another_LTFacility()\n",
    "\n",
    "another_lt.load_data()\n",
    "another_lt.prepare_data()\n",
    "another_lt.locate_data()\n",
    "another_lt.format_data()\n",
    "\n",
    "another_lt.data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complex functions can be considered, like for the newly defined class `Yet_Another_LTFacility` below (although we also could have overriden the methods of the previously defined class `Another_LTFacility`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yet_Another_LTFacility = config.facilityFactory(cat = FACILITY, meta = metadata)\n",
    "\n",
    "yet_another_preparator = another_preparator\n",
    "Yet_Another_LTFacility.prepare_data = yet_another_preparator\n",
    "\n",
    "def yet_another_locator(instance, delay = True): \n",
    "    # remember: we defined earlier the global variable geolocator as:\n",
    "    #    gcNominatim = functools.partial(geocoders.Nominatim(user_agent = PROJECT).geocode, \n",
    "    #                                   language = 'en') # or instance.lang\n",
    "    if delay is False:\n",
    "        new_geolocator = gcNominatim\n",
    "    else: \n",
    "        if delay is True:     delay = 1 # delay for requests to be sent to the geoservice\n",
    "        try:\n",
    "            assert isinstance(delay, int)\n",
    "        except: raise IOError(\"Wrong delay number\")\n",
    "        new_geolocator = extra.rate_limiter.RateLimiter(gcNominatim, min_delay_seconds = delay)\n",
    "    if 'place' not in instance.data.columns:\n",
    "        try:\n",
    "            instance.data['place'] = (\n",
    "                instance.data[['number', 'street', 'postcode', 'city']].astype(str)\n",
    "                .apply(lambda s: ', '.join(s), axis=1)\n",
    "            )\n",
    "        except: raise IOError(\"No place available\")\n",
    "    instance.data['lat'], instance.data['lon'] = (\n",
    "        zip(*instance.data['place']\n",
    "            .apply(new_geolocator)\n",
    "            .apply(lambda x: (x.latitude, x.longitude) if x != None else (np.nan, np.nan))\n",
    "           )\n",
    "    )\n",
    "Yet_Another_LTFacility.locate_data = yet_another_locator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And similarly process the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yet_another_lt = Yet_Another_LTFacility()\n",
    "\n",
    "yet_another_lt.load_data()\n",
    "yet_another_lt.prepare_data()\n",
    "yet_another_lt.locate_data()\n",
    "yet_another_lt.format_data()\n",
    "\n",
    "yet_another_lt.data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
